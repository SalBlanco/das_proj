{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 170,
      "id": "iFhZJXOVDowy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFhZJXOVDowy",
        "outputId": "195a0c79-c54b-454d-d3b2-ebe3b8e041e9"
      },
      "outputs": [],
      "source": [
        "# !pip install feedparser\n",
        "# !pip install arxiv\n",
        "# !pip install langchain\n",
        "# !pip install langgraph\n",
        "# !pip install langchain_openai\n",
        "# !pip install langchain_coreTh\n",
        "# !pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cKxzjtkEbyv0",
      "metadata": {
        "id": "cKxzjtkEbyv0"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_core.tools import tool\n",
        "from langchain.agents import load_tools\n",
        "\n",
        "import os\n",
        "import urllib, urllib.request\n",
        "import time\n",
        "import feedparser\n",
        "from datetime import datetime\n",
        "\n",
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "EDWFaw1QfkO5",
      "metadata": {
        "id": "EDWFaw1QfkO5"
      },
      "outputs": [],
      "source": [
        "# Set API key to call on LLM\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1f1762bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "obj = [{}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "ba05fc6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @tool\n",
        "def check_history(obj, filename='test.json'):\n",
        "    \"\"\"Write DAS paper information to output file if not already in history.\"\"\"\n",
        "    # Create history set for efficient lookup\n",
        "    history = set()\n",
        "    # Read through pre-existing json file\n",
        "    if os.path.exists(filename) and os.path.getsize(filename) > 0:\n",
        "        with open(filename, 'r') as file:\n",
        "            for line in file:\n",
        "                try:\n",
        "                    # Read each line, add to history set (unique values)\n",
        "                    existing_entry = json.loads(line.strip())\n",
        "                    history.add(json.dumps(existing_entry, sort_keys=True))\n",
        "                except json.JSONDecodeError:\n",
        "                        continue  # Skip invalid lines\n",
        "\n",
        "    # Extract entries that have not been added already\n",
        "    new_entries = [entry for entry in obj if json.dumps(entry, sort_keys=True) not in history]\n",
        "\n",
        "    # If there are new entries to add, open correponding file and dump JSON objects\n",
        "    if new_entries:\n",
        "        with open(filename, 'a') as file:\n",
        "            for entry in new_entries:\n",
        "                file.write(json.dumps(entry, sort_keys=True) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "78ddfd7d",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def write(obj, filename='test.json'):\n",
        "    \"\"\"Write DAS paper information to output file for records.\"\"\"\n",
        "    # Filepath where we will store found papers' information.\n",
        "    path = '/Users/salblanco/Desktop/das/das_proj/'\n",
        "\n",
        "    # If corresponding output folder does not exist, create it\n",
        "    os.listdir(path)\n",
        "    if 'out' not in os.listdir(path):\n",
        "        os.mkdir(path+'out')\n",
        "        os.chdir(path+'out')\n",
        "    else:\n",
        "        os.chdir(path+'out')\n",
        "        \n",
        "    # Create and/or append to output.json file to handle dictionary format\n",
        "    f = open('test.json', 'a')\n",
        "    # Write each entry on its own line\n",
        "    check_history(obj, filename)\n",
        "    # for entry in obj:\n",
        "    #     f.write(json.dumps(entry)+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "899940d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def paginate(papers_per_call, index, success=True):\n",
        "    \"\"\"Increment counter for pagination.\"\"\"\n",
        "    # Update index if successfully returned new papers; else, keep index the same\n",
        "    new_index = index + papers_per_call if success else index\n",
        "    print(f\"Paginating: index {index} â†’ {new_index} (success={success})\")\n",
        "    return new_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "5124ab9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "# adapted from https://info.arxiv.org/help/api/examples/python_arXiv_paging_example.txt\n",
        "def search(results_per_iteration, start):\n",
        "  \"\"\"Search for DAS papers\"\"\"\n",
        "\n",
        "  obj = []\n",
        "  \n",
        "  # Get current date + time\n",
        "  now = datetime.now()\n",
        "  today = now.strftime(\"%Y%m%d%H%M\")\n",
        "\n",
        "  # Base API query url\n",
        "  base_url = 'http://export.arxiv.org/api/query?'\n",
        "\n",
        "  # API search parameters for DAS papers from 1/01/2010 to today.\n",
        "  search_query = f'all:DAS+AND+all:distributed+AND+all:acoustic+AND+all:sensing+submittedDate:201001010000+TO+{today}'\n",
        "\n",
        "  # Number of seconds to wait beetween calls; recommended by arXiv documentation\n",
        "  wait_time = 3 \n",
        "\n",
        "  print(f'Searching arXiv for {search_query}')\n",
        "\n",
        "  while True:\n",
        "\n",
        "    print(f\"Results {start} - {start+results_per_iteration}\")\n",
        "\n",
        "    query = f'search_query={search_query}&start={start}&max_results={start+results_per_iteration}'\n",
        "\n",
        "    # GET request using the base_url and query\n",
        "    response = urllib.request.urlopen(base_url+query).read()\n",
        "\n",
        "    if not response or len(response) == 0:\n",
        "      print(\"No more results. Please try again.\")\n",
        "      break\n",
        "\n",
        "    # Parse the response using feedparser\n",
        "    feed = feedparser.parse(response)\n",
        "\n",
        "    # Run through each entry, and print out information\n",
        "    for entry in feed.entries:\n",
        "      paper_id = entry.id.split('/abs/')[-1]\n",
        "      title = entry.title\n",
        "      author = entry.author\n",
        "      summary = entry.summary if hasattr(entry, 'summary') else \"\"\n",
        "\n",
        "      # Format as a search result\n",
        "      content = f\"Paper ID: {paper_id}\\nTitle: {title}\\nAuthor: {author}\\nSummary: {summary}\"\n",
        "\n",
        "      # Add to results\n",
        "      obj.append({\n",
        "          'url': entry.id,  # Use arXiv URL\n",
        "          'content': content\n",
        "      })\n",
        "\n",
        "      print(\"arxiv-id: \", paper_id)\n",
        "      print(\"Title: \", title)\n",
        "      # feedparser v4.1 only grabs the first author\n",
        "      print(\"First Author: \", author)\n",
        "\n",
        "    # Break loop after extracting relevant information\n",
        "    break\n",
        "\n",
        "  # Sleep before calling API again\n",
        "  print(f\"Sleeping for {wait_time} seconds\")\n",
        "  time.sleep(wait_time)\n",
        "  \n",
        "  return obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "bdbbd790",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Need to add a tool so the agent can use the links it found to actually extract data availability statements and/or links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "3a8a6d11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Starting index for search\n",
        "index = 0\n",
        "# Number of papers retrieved\n",
        "papers_per_call = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "d3ddeddc",
      "metadata": {},
      "outputs": [],
      "source": [
        "index = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d174e5d5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "\n",
            "    You are a research assistant helping me find Distributed Acoustic Sensing (DAS) papers on arXiv. \n",
            "\n",
            "    **Task Instructions:**  \n",
            "    1. Use the `search` tool to retrieve the next 5 papers, starting from index 5.\n",
            "    2. Return the following details for each paper:  \n",
            "        - title  \n",
            "        - id  \n",
            "        - author\n",
            "        - link\n",
            "    3. If you are able to correctly search, use the return 'obj' from the 'search' tool as the input for the 'write' tool. \n",
            "    4. If you are able to correctly search, update the next index using the `paginate` tool. \n",
            "    5. Return the next starting index for future searches with the format: 'The next starting index for future searches is [index].'\n",
            "\n",
            "    **Notes:**  \n",
            "    - Always start from the most recent index and paginate correctly to avoid duplicates.  \n",
            "    - If no new papers are found, return an empty list along with the current index.  \n",
            "    \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  search (call_0bj60C8csqO9noQH6e90392j)\n",
            " Call ID: call_0bj60C8csqO9noQH6e90392j\n",
            "  Args:\n",
            "    results_per_iteration: 5\n",
            "    start: 5\n",
            "  paginate (call_F6miyA1nz4ORclpjoFn2dycm)\n",
            " Call ID: call_F6miyA1nz4ORclpjoFn2dycm\n",
            "  Args:\n",
            "    papers_per_call: 5\n",
            "    index: 5\n",
            "Searching arXiv for all:DAS+AND+all:distributed+AND+all:acoustic+AND+all:sensing+submittedDate:201001010000+TO+202503201058\n",
            "Results 5 - 10\n",
            "Paginating: index 5 â†’ 10 (success=True)\n",
            "arxiv-id:  2503.11622v1\n",
            "Title:  RNN-DAS: A New Deep Learning Approach for Detection and Real-Time\n",
            "  Monitoring of Volcano-Tectonic Events Using Distributed Acoustic Sensing\n",
            "First Author:  Carmen Benitez\n",
            "arxiv-id:  2312.08660v2\n",
            "Title:  Low-rank constrained multichannel signal denoising considering\n",
            "  channel-dependent sensitivity inspired by self-supervised learning for\n",
            "  optical fiber sensing\n",
            "First Author:  Tomoyuki Hino\n",
            "arxiv-id:  2305.04583v1\n",
            "Title:  Shallow shear-wave (SV) reflection surveying with distributed acoustic\n",
            "  sensing in Zuidbroek, the Netherlands\n",
            "First Author:  Guy Drijkoningen\n",
            "arxiv-id:  2006.15197v2\n",
            "Title:  Low-magnitude Seismicity with a Downhole Distributed Acoustic Sensing\n",
            "  Array -- examples from the FORGE Geothermal Experiment\n",
            "First Author:  William L. Ellsworth\n",
            "arxiv-id:  2209.05978v1\n",
            "Title:  A Distributed Acoustic Sensor System for Intelligent Transportation\n",
            "  using Deep Learning\n",
            "First Author:  Peter Hayward\n",
            "arxiv-id:  2304.08120v2\n",
            "Title:  DAS-N2N: Machine learning Distributed Acoustic Sensing (DAS) signal\n",
            "  denoising without clean data\n",
            "First Author:  Alex M. Brisbourne\n",
            "arxiv-id:  2303.07260v1\n",
            "Title:  Moment tensor inversion of perforation shots using distributed acoustic\n",
            "  sensing\n",
            "First Author:  Biondo Biondi\n",
            "arxiv-id:  2412.12743v1\n",
            "Title:  Training a Distributed Acoustic Sensing Traffic Monitoring Network With\n",
            "  Video Inputs\n",
            "First Author:  Ariel Lellouch\n",
            "arxiv-id:  2410.16278v1\n",
            "Title:  Edge Computing in Distributed Acoustic Sensing: An Application in\n",
            "  Traffic Monitoring\n",
            "First Author:  Robin Andre RÃ¸rstadbotnen\n",
            "arxiv-id:  2403.02791v1\n",
            "Title:  Intelligent Traffic Monitoring with Distributed Acoustic Sensing\n",
            "First Author:  Yingjiao Rong\n",
            "Sleeping for 3 seconds\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: paginate\n",
            "\n",
            "10\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  write (call_kKr47XCQjUioTdOdupNwye1x)\n",
            " Call ID: call_kKr47XCQjUioTdOdupNwye1x\n",
            "  Args:\n",
            "    obj: [{'title': 'RNN-DAS: A New Deep Learning Approach for Detection and Real-Time Monitoring of Volcano-Tectonic Events Using Distributed Acoustic Sensing', 'id': '2503.11622v1', 'author': 'Carmen Benitez', 'link': 'http://arxiv.org/abs/2503.11622v1'}, {'title': 'Low-rank constrained multichannel signal denoising considering channel-dependent sensitivity inspired by self-supervised learning for optical fiber sensing', 'id': '2312.08660v2', 'author': 'Tomoyuki Hino', 'link': 'http://arxiv.org/abs/2312.08660v2'}, {'title': 'Shallow shear-wave (SV) reflection surveying with distributed acoustic sensing in Zuidbroek, the Netherlands', 'id': '2305.04583v1', 'author': 'Guy Drijkoningen', 'link': 'http://arxiv.org/abs/2305.04583v1'}, {'title': 'Low-magnitude Seismicity with a Downhole Distributed Acoustic Sensing Array -- examples from the FORGE Geothermal Experiment', 'id': '2006.15197v2', 'author': 'William L. Ellsworth', 'link': 'http://arxiv.org/abs/2006.15197v2'}, {'title': 'A Distributed Acoustic Sensor System for Intelligent Transportation using Deep Learning', 'id': '2209.05978v1', 'author': 'Peter Hayward', 'link': 'http://arxiv.org/abs/2209.05978v1'}]\n",
            "  paginate (call_xmM60rS0hUqFbdAAU2OYFgrL)\n",
            " Call ID: call_xmM60rS0hUqFbdAAU2OYFgrL\n",
            "  Args:\n",
            "    papers_per_call: 5\n",
            "    index: 10\n",
            "Paginating: index 10 â†’ 15 (success=True)\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: paginate\n",
            "\n",
            "15\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here are the details for the next 5 papers on Distributed Acoustic Sensing (DAS) from arXiv:\n",
            "\n",
            "1. **Title:** RNN-DAS: A New Deep Learning Approach for Detection and Real-Time Monitoring of Volcano-Tectonic Events Using Distributed Acoustic Sensing  \n",
            "   **ID:** 2503.11622v1  \n",
            "   **Author:** Carmen Benitez  \n",
            "   **Link:** [arXiv](http://arxiv.org/abs/2503.11622v1)\n",
            "\n",
            "2. **Title:** Low-rank constrained multichannel signal denoising considering channel-dependent sensitivity inspired by self-supervised learning for optical fiber sensing  \n",
            "   **ID:** 2312.08660v2  \n",
            "   **Author:** Tomoyuki Hino  \n",
            "   **Link:** [arXiv](http://arxiv.org/abs/2312.08660v2)\n",
            "\n",
            "3. **Title:** Shallow shear-wave (SV) reflection surveying with distributed acoustic sensing in Zuidbroek, the Netherlands  \n",
            "   **ID:** 2305.04583v1  \n",
            "   **Author:** Guy Drijkoningen  \n",
            "   **Link:** [arXiv](http://arxiv.org/abs/2305.04583v1)\n",
            "\n",
            "4. **Title:** Low-magnitude Seismicity with a Downhole Distributed Acoustic Sensing Array -- examples from the FORGE Geothermal Experiment  \n",
            "   **ID:** 2006.15197v2  \n",
            "   **Author:** William L. Ellsworth  \n",
            "   **Link:** [arXiv](http://arxiv.org/abs/2006.15197v2)\n",
            "\n",
            "5. **Title:** A Distributed Acoustic Sensor System for Intelligent Transportation using Deep Learning  \n",
            "   **ID:** 2209.05978v1  \n",
            "   **Author:** Peter Hayward  \n",
            "   **Link:** [arXiv](http://arxiv.org/abs/2209.05978v1)\n",
            "\n",
            "The next starting index for future searches is 15.\n"
          ]
        }
      ],
      "source": [
        "# Track the last index\n",
        "tools = [search, paginate, write, check_history]\n",
        "memory = MemorySaver()\n",
        "model = ChatOpenAI(model_name=\"gpt-4o\")\n",
        "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"t15\"}}\n",
        "\n",
        "# Initial prompt\n",
        "for step in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=f\"\"\"\n",
        "    You are a research assistant helping me find Distributed Acoustic Sensing (DAS) papers on arXiv. \n",
        "\n",
        "    **Task Instructions:**  \n",
        "    1. Use the `search` tool to retrieve the next {papers_per_call} papers, starting from index {index}.\n",
        "    2. Return the following details for each paper:  \n",
        "        - title  \n",
        "        - id  \n",
        "        - author\n",
        "        - link\n",
        "    3. If you are able to correctly search, use the return 'obj' from the 'search' tool as the input for the 'write' tool. \n",
        "    4. If you are able to correctly search and write to the corresponding file, update the next index using the `paginate` tool. \n",
        "    5. Return the next starting index for future searches with the format: 'The next starting index for future searches is [index].'\n",
        "\n",
        "    **Notes:**  \n",
        "    - Always start from the most recent index and paginate correctly to avoid duplicates.  \n",
        "    - If no new papers are found, return an empty list along with the current index.  \n",
        "    \"\"\")]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        "    ):\n",
        "    step[\"messages\"][-1].pretty_print()\n",
        "    match = re.search(r\"The next starting index for future searches is (\\d+)\", str(step[\"messages\"][-1]))\n",
        "    if match:\n",
        "        index = int(match.group(1))  # Extract and convert to integer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fbcbce9",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "agent",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
